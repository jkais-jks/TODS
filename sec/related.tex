%!TEX root = ../main.tex
%\vspace{-1em}
\section{Related Work}\label{sec:related}

\noindent{\bf Task-agnostic incomplete data imputation.}
Data imputation has been widely studied for  years. Existing  methods can be divided into two categories: statistic-based methods and learning-based methods. The former one always uses the statistic information~\cite{DBLP:journals/tsmc/FarhangfarKP07, DBLP:conf/sigmod/MayfieldNP10} (like mean, median or mode) to impute the missing values. Also, some methods compute the similarity of the incomplete tuples to the complete tuples and use the most similar one to impute the missing values~\cite{altman1992introduction, DBLP:journals/artmed/JerezMGARMF10, DBLP:conf/isese/TwalaCS05}. Recently, to improve the imputation accuracy,   many learning-based methods focus on how to use ML to learn the data distribution (\eg MissForest imputation~\cite{DBLP:journals/bioinformatics/StekhovenB12}, MICE~\cite{royston2011multiple},  IIM~\cite{DBLP:conf/icde/ZhangSSW19}), and then  use the trained model to predict the missing values. Besides traditional ML models, some deep learning models are also used for data imputation (\eg  autoencoder~\cite{DBLP:journals/corr/GondaraW17, mccoy2018variational, DBLP:journals/pr/NazabalOGV20}, GANs~\cite{DBLP:journals/nn/SpinelliSU20, DBLP:conf/icml/YoonJS18}).
 
\noindent{\bf Coreset selection.}
Huang et al.~\cite{DBLP:conf/icml/HuangHLFD21} studied how to compute and continuously update the coreset while training. %, which aims  to utilize the loss of training tuples  to approximate the overall training loss of the entire training set. 
But it is rather time-consuming because of the training process. 
 To solve this problem, works~\cite{DBLP:conf/icml/CampbellB18, DBLP:journals/corr/BravermanFL16}   selected the coreset without training in advance, but they can only be customized to particular model types respectively. %The basic idea is to compute a sensitive score for each tuple, and the higher the score, the more likely the tuple should be in the coreset. 
 Another line of works~\cite{DBLP:conf/icml/MirzasoleimanBL20, DBLP:conf/nips/MirzasoleimanCL20, DBLP:conf/emnlp/KirchhoffB14} focused on selecting the coreset to approximate the full gradient without training in advance for multiple model types, which is regarded as an optimization problem that can be solved  by the three nested loops framework (see Section~\ref{subset:sigletable}).

In short, none of them considers coreset selection over incomplete data. Different from them, we make the first attempt to select coresets over incomplete data.

\noindent{\bf Data cleaning for ML.} Recently, there have  been several works that clean the data to optimize the ML model. 
In contrast to the above discussion about task-agnostic incomplete data imputation, data cleaning for ML is task-aware, which triggers new technical challenges.
SampleClean~\cite{DBLP:journals/debu/KrishnanWFGKM015} focuses on cleaning selected samples, so as to answer  SQL aggregate  queries  more efficiently, but it is not for any model.
%
 CPClean~\cite{DBLP:journals/pvldb/KarlasLWGC0020} proposes certain prediction to impute missing data for optimizing ML models. Different from us, it is customized to nearest neighbor classifiers rather than convex models solved by the gradient decent algorithm. 
  %
  BoostClean~\cite{DBLP:journals/corr/abs-1711-01299} regards data cleaning as a boosting problem that iteratively
 selects from a predefined set of cleaning algorithms, so as to continuously maximize the accuracy of  a validation set with training iteratively. 
Closer to our work is ActiveClean~\cite{DBLP:journals/pvldb/KrishnanWWFG16}, which progressively cleans the data tuples that are likely to much influence the model   measured by the gradients. 
%\cc{
Different from us,  given a budget $K$, we can select the coreset without training, but ActiveClean needs to train iteratively  and label a set of   validation  dataset.  We empirically show that our method outperforms ActiveClean on model accuracy and efficiency in Section~\ref{sec:exp}.
%}.
%(2) ActiveClean uses heuristics to measure the influence of tuples to the model gradients, which may not be accurate.
% Moreover, we  ActiveClean to the data imputation problem and compare with it in Section~\ref{sec:exp}.}

%ActiveClean iteratively estimates the impact of the dirty data and samples a batch of dirty data that have the most impact on the model. Then, ActiveClean asks human to clean the batch of dirty data. The main difference between ActiveClean and \ours is ActiveClean needs to iteratively train the model, since it relies on the feedback from both human and model to estimate the impact of the dirty data.


\noindent{\bf Data Preparation for AI.}
Data preparation~\cite{chai2020crowdchart} can be utilized to improve the effectiveness of ML model, including data discovery~\cite{liu2021automatic, chai2022selective, liu2022feature},  data cleaning~\cite{hao2020outdated,chai2020human}, data labeling~\cite{chai2016cost, chai2018partial, li2018cdb}, data cleaning~\cite{miao2022experimental, gao2018query,miao2018incomplete, miao2021efficient,wu2022interactive,ge2020hybrid} and data exploration~\cite{qin2020interactively,qin2021ranking}.